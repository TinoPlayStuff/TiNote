---
tags: [yolo]
last_modified_at: 2022-06-27T15:58:41+08:00
last_updated: 2022-06-27T15:58:41+08:00
date: 2022-06-27T15:58:41+08:00
---
# yolov5

yolov5 is a fast, easy to use dnn model


## temp

- version description
  - use yolov5-4.0 to train model
    - use 4.0 to convert, use post_process to explain result
    - use 4.0-tflite, need to use post_process_xx(tflite) 
    - use 5.x to convert, ...
- get coco data
  - use script in yolov5
  - YOLO-Coco-Dataset-Custom-Classes-Extractor too slow to download data
- convert coco to yolo, extract classes interesting to us
  - YOLO-Coco-Dataset-Custom-Classes-Extractor has codes
  - [developpaper: yolov4 in docker with coco data]
  - <https://github.com/ultralytics/JSON2YOLO>
  - using gluon [medium: Selecting and preparing a specific subset of images 
    from the COCO dataset to train YOLO Object 
    Detection Model](https://bit.ly/medium_coco2yolo)
- discussion about mosaic
  - <https://www.zhihu.com/question/473350307>
  - <https://github.com/ultralytics/yolov5/issues/2151>
  - "Data Augmentation 里面需要强调的一点是： 要在训练结束前的15个 epoch 关掉 Mosaic 
    和 Mixup ，这对于 YOLOX 非常重要。"
    ![ ](..\_resources\1d4ecd5a3bd04536b23aa683f6ded4b3.png)

## tips

- parameter discussion
  - `--cache disk`: create cache on disk, on .88, it helps (from 8'57" to 7'45")
    - it'l create `labels_npy` folder, better remove it for a new run
- epoch, official says try 300, 600, 1200, ...
- 


## yolov5-6.1

- install: modify requirement.txt, may encounter errors, 
  - try to uninstall numpy first, and type command to install Cython and 
    pycocotools
- commands:
  - **get pre-trained model**:
    ```python
    model = torch.hub.load('ultralytics/yolov5', 'yolov5n')
    ```
  - **detect**:
    ```shell
    python detect.py --save-txt --classes 0 \
    --source ../data_test/Qnap_high/yolo/images/ \
    --weights pre_trained_models/yolov5n.pt --project test/example
    ```
  - **export**:
    ```shell
    python export.py --weights pre_trained_models/yolov5n.pt \
    --include onnx \
    --img 480 --batch 1
    ```
    - 用 v4.0 來 export .onnx 是可行的
      - 需在 common.py 中增加 SPPF class
  - **export (edgetpu)**
    - [20220330] need to remove --img 
      ```shell
       python export.py --weights pre_trained_models/yolov5n.pt \
                        --include edgetpu --batch 1
      ```
  - **train**
    ```sh
    # on 126
    python train.py --project ./runs/r4_yv5n2_480_CrowdRgbdSafety \
                --img 480 --batch-size 16 --epoch 200 \
                --data ./data/CrowdRgbdSafety_c2_1.yaml \
                --cfg ./models/yolov5n_c2.yaml \
                --hyp ./data/hyps/hyp.scratch-low.yaml \
                --weights ./pre_trained_models/yolov5n.pt \
                --multi-scale --workers 8 --resume
    ```
    this is for multiple gpu
    ```sh
    python -m torch.distributed.launch --nproc_per_node 2 \
       train.py --project ./runs/r4_yv5n2_480_CrowdRgbdSafety \
                --img 480 --batch-size -1 --epoch 200 \
                --data ./data/CrowdRgbdSafety_c2_1.yaml \
                --cfg ./models/yolov5n_c2.yaml \
                --hyp ./data/hyps/hyp.scratch_4.yaml \
                --weights ./pre_trained_models/yolov5n.pt \
                --cache-images --multi-scale --device 1,2
    ```

### rknn optimize

- ref: 
  - <https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo>
    - <https://github.com/airockchip/yolov5>
    - <https://github.com/EASY-EAI/yolov5>
- my step:
  1. use relu
  2. modify exporter (Detect())
     - this will fail the train()
  3. modify tf.py for so that tflite exporter know the relu
- working:
  - convert model on .126 (/home/tino/curr_proj/rknn_convert/demo)
    - using (rknn_conv) venv
    - note, currently use `rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]],output_tensor_type="int8")`, but maybe it could omit `output_tensor_type="int8"`
    - sample code: 
      ```bash
      python test_onnx.py ....../weights/best.onnx --target rk3568 >> log.txt
      ```
  - ~~build application on 10.33.72.21 (admin/d9323003)~~
  - build application on 10.33.72.24:10022
    - docker exec -it tino_build bash
    - see "~/tino_mount/rknn_ssd_demo_static/app/build_demo.sh"
      - neglect the reported type of input and output nodes, just feed uint8 
        and ask float return.
  - from Carl: [rknn_carl] <- "not ready yet, maybe come here later" 
  - from <https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo/convert_rknn_demo/yolov5/onnx_models> 
    - a yolov5 example, but it's .onnx model has different shapes to it's readme



## yolov5 (pytorch)

- commands
  - train:  
    ```bash
    CUDA_VISIBLE_DEVICES="0" python train.py --project runs05/ --img 640 \
    --batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
    --cfg ./models/yolov5ss2.yaml --weights runs05/exp3/weights/best.pt

    CUDA_VISIBLE_DEVICES="0" python train.py --project runs05/ --img 640 \
    --batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
    --cfg ./models/yolov5ss2.yaml --resume
    ```

  - fine tune:
    ```bash
    CUDA_VISIBLE_DEVICES="0" python train.py --project runs05/ --img 640 \ 
    --batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
    --cfg ./models/yolov5ss2.yaml --hyp data/hyp.finetune_02.yaml \
    --weights runs05/exp5/weights/best.pti
    ```

  - export:
    ```bash
    python ./models/export.py --weights best_crowdhuman_s1.pt --img 640 \
    --batch 1
    ```

  - detect:
    - older code:
    ```bash
    python detect.py --save-txt \
    --source /content/Safety_Helmet_Train_dataset/score/images/train/ \
    --weight weights/yolov5x.py --output inference/2/out_train
    ```

    - newer code:  
    ```bash
    python detect.py --save-txt --classes 0 \
    --source /content/Safety_Helmet_Train_dataset/score/images/train/ \
    --weights weights/yolov5x.pt --project inference/2/out_train
    ```


## yolov5 tflite  

- [https://github.com/ultralytics/yolov5/issues/1090](https://j.mp/34zrhS8) 
  convert to tflite successfully. (Oct 7, 2020)
- [https://github.com/ultralytics/yolov5/issues/232](https://j.mp/3pgtbyY) 
  (Jun 29, 2020)
  - describe a way to comvert to .onnx -> .pb -> .tflite
  - [google colab](https://j.mp/34RnPCD) example codes to 
    **build tensorflow lite**

    ```python
    ! sudo apt install bazel
    ! sudo apt install g++ unzip zip
    ! wget https://github.com/bazelbuild/bazel/releases/download/3.3.0/bazel-3.3.0-installer-linux-x86_64.sh
    ! chmod +x bazel-3.3.0-installer-linux-x86_64.sh
    ! bash bazel-3.3.0-installer-linux-x86_64.sh
    ! bazel build tensorflow/contrib/lite/toco:toco
    ```

  - zldrobit suggest tf-android (#1127) here (Nov 3, 2020)
- [https://github.com/ultralytics/yolov5/issues/453](https://j.mp/3mDoxct) 
  (Jul 20, 2020) 
  also encounted the error while converting .onnx -> .tflite

  ```bash
  error: 'tf.AddV2' op is neither a custom op nor a flex op
  ```

  - zldrobit suggest **tf-export** (#959) (Sep 12, 2020)
  - [https://github.com/ultralytics/yolov5/issues/453#issuecomment-692287842]
    encounted inference problem with zldrobit's solution (if tensorflow version 
    not 2.3 while inference)  

    ```ba
    ValueError: Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3'
    ```

  - [https://github.com/ultralytics/yolov5/issues/453#issuecomment-694194659]
    zldroit indicate that tflite 2.0, 2.1 and 2.2 have bug
    - irrelevant bug (only occur with GPU), but may be a reason to build 
      tflite 2.3.x
- [https://github.com/ultralytics/yolov5/pull/959] (Sep 12, 2020)
  - [https://github.com/ultralytics/yolov5/pull/959#issuecomment-694548889] 
    resize_nearest_neighbor are not compatible with the edge TPU
    - resize_nearest_neighbor has 3D input/output limitations. 
      [https://github.com/ultralytics/yolov5/pull/959#issuecomment-694602286]
- onnx to tensorflow [https://www.jianshu.com/p/fd1fcde8feee]
  - 做用onnx-tf轉換.onnx到.pb時，出現問題

    ```bash
    onnx-tf convert -i ../../yolov5_working/yolov5/best_crowdhuman_s1.onnx \
    -o ../../yolov5_working/yolov5/best_crowdhuman_s1.pb  
    ModuleNotFoundError: No module named 'tensorflow_addons'
    ```

  - 轉至tflite時，有另一問題

    ```bash
    error: 'tf.AddV2' op is neither a custom op nor a flex op
    ```

    [https://github.com/ultralytics/yolov5/pull/959] 似乎有解，但要tensorflow2.3
    (onnx-tf建議tensorflow2.2)
    - onnx-tf現在(20201201)也建議tensorflow2.3.1，still don't work with onnx-tf

- **tf-android** (yolov5) 
  [https://github.com/zldrobit/yolov5/tree/1f8499c047126d678f631b8ee73681c913c64995]
  - 16-tflite

    ```bash
    PYTHONPATH=. python models/tf.py --weight ../model/best.pt \ 
    --cfg ../model/yolov5ss2.yaml --img 640 --no-tfl-detect
    python detect.py --weights ../model/best-fp16.tflite --cfg ../model/yolov5ss2.yaml \
    --img 640 --source ../data/273275,cd061000af95f691.jpg --tfl-detect
    ```

  - 8-tflite
  
    ```bash
    PYTHONPATH=. python models/tf.py --weights ../model/best.pt \ 
    --cfg ../model/yolov5ss2.yaml --img 640 --tfl-int8 --no-tfl-detect \
    --source ../data/CrowdHumanYv5_100img/ --ncalib 100 
  
    python detect.py --weights ../model/best-int8.tflite --cfg ../model/yolov5ss2.yaml \
    --img 640 --source ../data/273275,cd061000af95f691.jpg --tfl-int8 --tfl-detect
    ```

    ```bash
    PYTHONPATH=. python models/tf.py --weight \
    ../../yolov5_working/yolov5/runs_yv5ss1_640_high_top/exp_25_4/weights/best_01364.pt \
    --cfg ../../yolov5_working/yolov5/models/yolov5ss1.yaml \
    --img 640 --tfl-int8 --source \
    ../../yolov5_working/data/top-view-multi-person-tracking-2020-ss/train/images \
    --ncalib 100
    ```

  - [20201201] 測試時，tf-only-export 無法做uint8的偵測
  - [20210308] 發現glenn-jocher也對此有許多contribution
    - <https://github.com/ultralytics/yolov5/issues/1847>
    - <https://github.com/ultralytics/yolov5/issues/1981>
  
  - [20210330]
    - convert
      ```bash
      PYTHONPATH=. python3  models/tf.py --weight weights/yolov5s.pt --cfg models/yolov5s.yaml --img 320 --tfl-int8 --source /data/dataset/coco/coco2017/train2017 --ncalib 100

      PYTHONPATH=. python3 models/tf.py \
      --weight ../../yolov5_working_2888/yolov5-4.0/runs_4.0_yv5ss1_480_high_top/exp/cvt/best_00358_4.0_480.pt \
      --cfg ../../yolov5_working_2888/yolov5-4.0/models/yolov5ss1.yaml \
      --img 480 --tfl-int8 \
      --source ../../yolov5_working_2888/data/top-view-multi-person-tracking-2020_Yv5/images/train \
      --ncalib 100
      ```
      now need tensorflow 2.4, with 2.3.1, got:
      ```bash
      TFLite export failure: Quantization not yet supported for op:
      Traceback (most recent call last):
        File "models/tf.py", line 479, in <module>
          tflite_model = converter.convert()
        File "/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 830, in convert
          return super(TFLiteKerasModelConverterV2,
        File "/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 638, in convert
          result = self._calibrate_quantize_model(result, **flags)
        File "/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 450, in _calibrate_quantize_model
          return calibrate_quantize.calibrate_and_quantize(
        File "/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/optimize/calibrator.py", line 95, in calibrate_and_quantize
          return self._calibrator.QuantizeModel(
      RuntimeError: Quantization not yet supported for op:
      ```
    - detect
      ```bash
      CUDA_VISIBLE_DEVICES="1" python3 detect.py \
      --weight ../../yolov5_working_2888/yolov5-4.0/runs_4.0_yv5ss1_480_high_top/exp/cvt/best_00358_4.0_480-int8.tflite \
      --img 480 --tfl-int8 --source ../../yolov5_working_2888/data_test/top
      ```
      - the output detail:
        ```bash
        [{'name': 'Identity', 'index': 424, 'shape': array([    1, 14175,     6], dtype=int32), 'shape_signature': array([    1, 14175,     6], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.008681188337504864, 2), 'quantization_parameters': {'scales': array([  0.0086812], dtype=float32), 'zero_points': array([2], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
        ```
  
- **edgetpu-minimal-example** 
  [https://github.com/Namburger/edgetpu-minimal-example]
  - to use tensorflow 2.3.1, change
  
    ```makefile
    set(TENSORFLOW_COMMIT fcc4b966f1265f466e82617020af93670141b009)
    #set(TENSORFLOW_COMMIT d855adfc5a0195788bf5f92c3c7352e638aa1109)
    ```

  - to avoid compile error

    ```makefile
    set(OTHERS
    -L/usr/lib/x86_64-linux-gnu
    -ldl) 
    target_link_libraries(minimal model_utils ${TF_LITE_LIB} ${TF_ET_SRC_LIB} ${OTHERS})
    ```
    
  - coral::read_bmp() cause error
    - it only accept .bmp
  - coral::RunInference cause "Segmentation fault"
    - it doesn't happen with int8 model
  - Need care nchw/nhwc
  - Need care about int8->float with int8 model
  - 若用預設的tensorflow2.1.2
    - fp32 or fp16:

      ```ba
      ERROR: Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3'
      ERROR: Registration failed.
      ```

    - int8:
  
      ```ba
      ERROR: Didn't find op for builtin opcode 'LEAKY_RELU' version '2'
      ERROR: Registration failed.
      ```
      

### edgetpu model

- minimal sample git performs ok
  - originally it based on tf 2.1 
    (d855adfc5a0195788bf5f92c3c7352e638aa1109 20200124)
    - yolov5 model needs tf 2.3.1 (because the converter (tf-android))
  - built with tf 2.3.1, with carl's .so .a, (probabily tf 2.1)
    (f394a768719a55b5c351ed1ecab2ec6f16f99dd4 20200409)
    - sample model: can run, identical with original (tf 2.1), cpu results
      similar to gpu results   
      - ori + cpu
        ```bash
        edgetpu-minimal-example_ori_tf2.3.1/build# ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt
        ------
        Class: tabby, tabby cat
        Score: 0.046875
        ------
        Class: tiger cat
        Score: 0.109375
        ------
        Class: Siamese cat, Siamese
        Score: 0.00390625
        ------
        Class: Egyptian cat
        Score: 0.804688
        ------
        Class: doormat, welcome mat
        Score: 0.0078125
        ------
        Class: radiator
        Score: 0.0078125
        ------
        Class: space heater
        Score: 0.0117188
        ```
      - ori + tpu
        ```bash
        ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant_edgetpu.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt
        ERROR: Internal: Unsupported data type in custom op handler: 36999120
        ERROR: Node number 0 (edgetpu-custom-op) failed to prepare.

        Failed to allocate tensors.
        Segmentation fault
        ```
      - with carl's lib + cpu
        ```bash
        edgetpu-minimal-example_ori_tf2.3.1_carl/build# ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt
        ------
        Class: tabby, tabby cat
        Score: 0.046875
        ------
        Class: tiger cat
        Score: 0.109375
        ------
        Class: Siamese cat, Siamese
        Score: 0.00390625
        ------
        Class: Egyptian cat
        Score: 0.804688
        ------
        Class: doormat, welcome mat
        Score: 0.0078125
        ------
        Class: radiator
        Score: 0.0078125
        ------
        Class: space heater
        Score: 0.0117188
        ```
      - with carl's lib + tpu
        ```bash
        edgetpu-minimal-example_ori_tf2.3.1_carl/build# ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant_edgetpu.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt
        ------
        Class: tabby, tabby cat
        Score: 0.0390625
        ------
        Class: tiger cat
        Score: 0.128906
        ------
        Class: Siamese cat, Siamese
        Score: 0.00390625
        ------
        Class: Egyptian cat
        Score: 0.792969
        ------
        Class: doormat, welcome mat
        Score: 0.0078125
        ------
        Class: radiator
        Score: 0.0078125
        ------
        Class: space heater
        Score: 0.0117188
        ```
    - yolov5 model: can only run with carl's lib file, but cpu - gpu results
      somewhat similar 
      - [cpu](..\_resources\be01ab5522dd4cb6b8c203705ef1f803.txt) 
        [tpu](..\_resources\15a2fbdce4484f35a9609f21142b3030.txt)
    - yolov5_2020 model:
      - ori cpu = carl cpu != carl tpu
    - yolov5 model:
      - ori cpu = carl cpu ~ carl tpu



#### minimal sample

- follow <https://coral.ai/docs/edgetpu/compiler/#system-requirements>
  ```bash
  curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
  echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list
  sudo apt-get update
  sudo apt-get install edgetpu-compiler
  ```
  ```bash
  edgetpu_compiler -sa best_01364-2020_int8.tflite
  ```
  option "a" for ... 


#### build edtetpu library

- note: 
  - in minimial sample, libedgetpu.so.1 is pre-built, libtensorflow-lite.a
    is built along with the execute
  - "tflite_runtime package": 
    - to execute tflite model with python, can install just the 
      "Tensorflow Lite interpreter", instead of all TensorFlow packages. 
      The simplified Python package is so called "tflite_runtime" 
      [https://www.tensorflow.org/lite/guide/python]

- survey
  - supported operations [tpu operations]: 
    - Operation version not supported: RESIZE_NEAREST_NEIGHBOR, LEAKY_RELU, 
      TRANSPOSE, 
    - somewhat supported: QUANTIZE, STRIDED_SLICE     
  - a sample [libedgetpu on raspberry pi]:
    - build libedgetpu.so ref [https://github.com/google-coral/libedgetpu/]
      Make sure to change the commit, then copy the libedgetpu.so
      - install bazel first [install bazel] 
  - disscussion with yolov5 on edgetpu [yolov5_tpu]
  - carl's build version: [1]


#### error

- ERROR: Didn't find op for builtin opcode 'TRANSPOSE_CONV' version '3'
  - <https://github.com/google-coral/edgetpu/issues/147>
  - best guess: tensorflow too new
  - The sweet spot is with tensorflow2.2 [20200616]
- TRANSPOSE
  - <https://github.com/google-coral/edgetpu/issues/193#issuecomment-718713474>
  - may use keras to avoid TRANSPOSE

    
    

## yolov5 (tensorflow)

- [YoloV5的原理与实现：附TensorFlow版开源](https://zhuanlan.zhihu.com/p/342522198)
  - <https://github.com/LongxingTan/Yolov5>


## yolov5 (openvino)

- <https://github.com/SamSamhuns/yolov5_export_cpu>
  - 指令教學 pytorch -> onnx -> openvino
- <https://github.com/PINTO0309/PINTO_model_zoo>
  - seems older
- <https://github.com/ultralytics/yolov5/issues/891>
  - <https://cdrdv2.intel.com/v1/dl/getContent/633562>
    - 一份intel官方文件
- <https://blog.csdn.net/qq_35975447/article/details/117440167>
- <https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo>
  - can use this for testing model
- newer openvino (since 2021.3) may have yolov5 adapter
  - <https://git.io/JE1uD>
- <https://learnopencv.com/post-training-quantization-with-openvino-toolkit>


### yv5 openvino quantization

- ref
  - 實例：
    - <https://blog.csdn.net/sandmangu/article/details/120331202>
    - <https://www.fatalerrors.org/a/19511zE.html>
  - prepare data:
    - <https://github.com/RapidAI/YOLO2COCO>
    - yolox and openvino don't know yolo data format 
- working method：
  1. convert to onnx with yolov5 5.x
  2. when converting to openvino, 
     - use scale set input to [0.f, 255.f]
     - assign only one output node
  3. when quantizing,
     - ignore lower several nodes








### log

- from <https://github.com/SamSamhuns/yolov5_export_cpu>
  - convert to onnx
    - ~~from other discussions: modify export.py to use opset 10~~  
      openvino 2021 remove resize opset-10 restriction
    - export code
      ```python
      python models/export.py \
      --weights r4_yv5ss2_480_CrowdRgbdSafety/exp2/weights/best.pt \
      --img 480 --batch 1
      ```
  - onnx detect  
    ```
    python detect_onnx.py -m image -i "media/2.jpg" -c 2 \
    -ox ../yolov5-4.0/r4_yv5ss2_480_CrowdRgbdSafety/exp2/weights/best.onnx
    ```
    <img width="480" height="32" src="..\_resources\ca86164b72dd4df0b0f7c0e664de5a83.png"/>
  - convert to openvino
    ```python
    python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \
          --progress \
          --input_shape [1,3,480,480] \
          --input_model ../yolov5-4.0/r4_yv5ss2_480_CrowdRgbdSafety/exp2/weights/best.onnx \
          --output_dir models/CrowdRgbdSafety \
          --data_type half
    ```
  - openvino detect
    ```bash
    python detect_openvino.py -m image -i "media/2.jpg" \
    --model_xml models/CrowdRgbdSafety/best.xml \
    --model_bin models/CrowdRgbdSafety/best.bin
    ```



## method

- reading:
  - <https://github.com/ultralytics/yolov5/discussions/6717>

- loss
  - 採用 yolov3，但從code上看來不同
    - (先看)https://blog.csdn.net/qq_38253797/article/details/119444854 
    - https://www.whcsrl.com/blog/1018544

- **focus:**
  - 分區下採樣  
    ![ ](..\_resources\1df2ecb445ab453d9f15ab9f8293d252.png)
  - want to reduce the computation, but the performance varies on different devices. 
  - removed in v6.0  
    <https://github.com/ultralytics/yolov5/issues/6257>



## Model conversion

- A page contains many models converted to various platforms
  - A page contains many models converted to various platforms
    - [https://github.com/PINTO0309/PINTO_model_zoo]



## variation

- yolov5-lite
  - <https://github.com/ppogg/YOLOv5-Lite>
  - ref: <https://zhuanlan.zhihu.com/p/400545131>
  - ref 1: <https://www.eet-china.com/mp/a116564.html>
    - shufflenet, PAN
  - 在其上復現 picodet <https://zhuanlan.zhihu.com/p/446787775>
- airockchip
  - <https://github.com/airockchip/rknn_model_zoo>
- ppyolo
  - <https://github.com/PaddlePaddle/PaddleDetection> 



................................................................................

#yolo #test_tag1 #test_tag2


[developpaper: yolov4 in docker with coco data]:https://bit.ly/developpaper_yolov4  
[libedgetpu on raspberry pi]:https://github.com/google-coral/edgetpu/issues/229#issuecomment-704576309  
[tpu operations]:https://coral.ai/docs/edgetpu/models-intro/#supported-operations  
[yolov5_tpu]:https://github.com/google-coral/edgetpu/issues/272  
[1]:https://github.com/google-coral/libedgetpu/blob/master/workspace.bzl#L8  
[install bazel]:https://docs.bazel.build/versions/master/install-ubuntu.html  
 
